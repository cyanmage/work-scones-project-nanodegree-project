{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eee91bb",
   "metadata": {},
   "source": [
    "## Point 2 :  Modify your event driven workflow: can you rewrite your Lambda functions so that the workflow can process multiple image inputs in parallel? Can the Step Function \"fan out\" to accomodate this new workflow?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6847eed4",
   "metadata": {},
   "source": [
    "#### Response\n",
    "- No lambda function code has been replaced. \n",
    "- The map feature of the step function service has been used instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ea7c4f",
   "metadata": {},
   "source": [
    "---\n",
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e58e4706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5b61616a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jsonlines\n",
      "  Downloading jsonlines-3.0.0-py3-none-any.whl (8.5 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages (from jsonlines) (20.3.0)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages (from jsonlines) (4.0.1)\n",
      "Installing collected packages: jsonlines\n",
      "Successfully installed jsonlines-3.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1233538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "import random, json, jsonlines\n",
    "from time import strftime\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9bc83ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "region = sess.boto_region_name\n",
    "\n",
    "import boto3, os\n",
    "\n",
    "client_s3 = boto3.Session().resource('s3')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "366ea519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sagemaker-us-east-1-416312206633',\n",
       " 'us-east-1',\n",
       " 'arn:aws:iam::416312206633:role/service-role/AmazonSageMaker-ExecutionRole-20211216T204468')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.default_bucket(), region, role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20d8e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_bucket = 'batch-classification-scones-project'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "6afb1630",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!aws s3 rm s3://batch-classification-scones-project --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f0e776",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!aws s3 rm s3://batch-classification-scones-project/train_batch_classification --recursive\n",
    "#!aws s3 rm s3://batch-classification-scones-project/test_batch_classification --recursive\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "31139900",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./train_batch_classification\n",
    "!rm -rf ./test_batch_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f439aef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./cifar-100-python/meta\", \"rb\") as f:\n",
    "    dataset_meta = pickle.load(f, encoding='bytes')\n",
    "\n",
    "with open(\"./cifar-100-python/test\", \"rb\") as f:\n",
    "    dataset_test = pickle.load(f, encoding='bytes')\n",
    "\n",
    "with open(\"./cifar-100-python/train\", \"rb\") as f:\n",
    "    dataset_train = pickle.load(f, encoding='bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6eb561bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "0      19\n",
       "1      29\n",
       "2       0\n",
       "3      11\n",
       "4       1\n",
       "...    ..\n",
       "49995  80\n",
       "49996   7\n",
       "49997   3\n",
       "49998   7\n",
       "49999  73\n",
       "\n",
       "[50000 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dataset_train[b'fine_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a8f3545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0  count\n",
       "0           \n",
       "0        500\n",
       "1        500\n",
       "2        500\n",
       "3        500\n",
       "4        500\n",
       "..       ...\n",
       "95       500\n",
       "96       500\n",
       "97       500\n",
       "98       500\n",
       "99       500\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_fine_labels = pd.DataFrame(dataset_train[b'fine_labels'])\n",
    "pd.crosstab(index=pd_fine_labels[0], columns=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9349c4f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99    500\n",
       "36    500\n",
       "26    500\n",
       "27    500\n",
       "28    500\n",
       "     ... \n",
       "69    500\n",
       "70    500\n",
       "71    500\n",
       "72    500\n",
       "0     500\n",
       "Length: 100, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_fine_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f01379a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "0      19\n",
       "1      29\n",
       "2       0\n",
       "3      11\n",
       "4       1\n",
       "...    ..\n",
       "49995  80\n",
       "49996   7\n",
       "49997   3\n",
       "49998   7\n",
       "49999  73\n",
       "\n",
       "[50000 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(dataset_meta[b'fine_label_names'][dataset_train[b'fine_labels'][n]])\n",
    "pd.DataFrame(dataset_train[b'fine_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecfb1129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'apple',\n",
       " b'aquarium_fish',\n",
       " b'baby',\n",
       " b'bear',\n",
       " b'beaver',\n",
       " b'bed',\n",
       " b'bee',\n",
       " b'beetle',\n",
       " b'bicycle',\n",
       " b'bottle',\n",
       " b'bowl',\n",
       " b'boy',\n",
       " b'bridge',\n",
       " b'bus',\n",
       " b'butterfly',\n",
       " b'camel',\n",
       " b'can',\n",
       " b'castle',\n",
       " b'caterpillar',\n",
       " b'cattle',\n",
       " b'chair',\n",
       " b'chimpanzee',\n",
       " b'clock',\n",
       " b'cloud',\n",
       " b'cockroach',\n",
       " b'couch',\n",
       " b'crab',\n",
       " b'crocodile',\n",
       " b'cup',\n",
       " b'dinosaur',\n",
       " b'dolphin',\n",
       " b'elephant',\n",
       " b'flatfish',\n",
       " b'forest',\n",
       " b'fox',\n",
       " b'girl',\n",
       " b'hamster',\n",
       " b'house',\n",
       " b'kangaroo',\n",
       " b'keyboard',\n",
       " b'lamp',\n",
       " b'lawn_mower',\n",
       " b'leopard',\n",
       " b'lion',\n",
       " b'lizard',\n",
       " b'lobster',\n",
       " b'man',\n",
       " b'maple_tree',\n",
       " b'motorcycle',\n",
       " b'mountain',\n",
       " b'mouse',\n",
       " b'mushroom',\n",
       " b'oak_tree',\n",
       " b'orange',\n",
       " b'orchid',\n",
       " b'otter',\n",
       " b'palm_tree',\n",
       " b'pear',\n",
       " b'pickup_truck',\n",
       " b'pine_tree',\n",
       " b'plain',\n",
       " b'plate',\n",
       " b'poppy',\n",
       " b'porcupine',\n",
       " b'possum',\n",
       " b'rabbit',\n",
       " b'raccoon',\n",
       " b'ray',\n",
       " b'road',\n",
       " b'rocket',\n",
       " b'rose',\n",
       " b'sea',\n",
       " b'seal',\n",
       " b'shark',\n",
       " b'shrew',\n",
       " b'skunk',\n",
       " b'skyscraper',\n",
       " b'snail',\n",
       " b'snake',\n",
       " b'spider',\n",
       " b'squirrel',\n",
       " b'streetcar',\n",
       " b'sunflower',\n",
       " b'sweet_pepper',\n",
       " b'table',\n",
       " b'tank',\n",
       " b'telephone',\n",
       " b'television',\n",
       " b'tiger',\n",
       " b'tractor',\n",
       " b'train',\n",
       " b'trout',\n",
       " b'tulip',\n",
       " b'turtle',\n",
       " b'wardrobe',\n",
       " b'whale',\n",
       " b'willow_tree',\n",
       " b'wolf',\n",
       " b'woman',\n",
       " b'worm']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_meta[b'fine_label_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40c3359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#types_vehicles = [b'bus', b'bicycle', b'pickup_truck', b'rocket', b'motorcycle', b'streetcar', b'tank', b'tractor', b'train']\n",
    "types_vehicles = [b'bicycle', b'motorcycle',  b'streetcar', b'rocket', b'tractor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7aed1279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 48, 69, 81, 89]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# liste 1 : dataset_meta[b'fine_label_names']\n",
    "# liste 2 : type_vehicles\n",
    "\n",
    "# Indices list of matching element from other list\n",
    "# Using list comprehension + set() + enumerate()\n",
    "temp = set(types_vehicles)\n",
    "numbers_type_vehicle = [i for i, val in enumerate(dataset_meta[b'fine_label_names']) if val in temp]\n",
    "numbers_type_vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90dece5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct the dataframe\n",
    "df_train = pd.DataFrame({\n",
    "    \"filenames\": dataset_train[b'filenames'],\n",
    "    \"labels\": dataset_train[b'fine_labels'],\n",
    "    \"row\": range(len(dataset_train[b'filenames']))\n",
    "})\n",
    "\n",
    "# Drop all rows from df_train where label is not in types_vehicles\n",
    "df_train = df_train[df_train['labels'].isin(numbers_type_vehicle)]\n",
    "\n",
    "# Decode df_train.filenames so they are regular strings\n",
    "df_train[\"filenames\"] = df_train[\"filenames\"].apply(\n",
    "    lambda x: x.decode(\"utf-8\")\n",
    ")\n",
    "\n",
    "\n",
    "df_test = pd.DataFrame({\n",
    "    \"filenames\": dataset_test[b'filenames'],\n",
    "    \"labels\": dataset_test[b'fine_labels'],\n",
    "    \"row\": range(len(dataset_test[b'filenames']))\n",
    "})\n",
    "\n",
    "# Drop all rows from df_test where label is not in types_vehicles\n",
    "df_test = df_test[df_test['labels'].isin(numbers_type_vehicle)]\n",
    "\n",
    "# Decode df_test.filenames so they are regular strings\n",
    "df_test[\"filenames\"] = df_test[\"filenames\"].apply(\n",
    "    lambda x: x.decode(\"utf-8\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d53cfa5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"filenames\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19d5edd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"filenames\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd2ad0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenames</th>\n",
       "      <th>labels</th>\n",
       "      <th>row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bike_s_000682.png</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>bike_s_000127.png</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>streetcar_s_000663.png</td>\n",
       "      <td>81</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>tractor_s_001723.png</td>\n",
       "      <td>89</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>tractor_s_000104.png</td>\n",
       "      <td>89</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>bulldozer_s_000433.png</td>\n",
       "      <td>89</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>minuteman_s_000073.png</td>\n",
       "      <td>69</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>icbm_s_000392.png</td>\n",
       "      <td>69</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>cycle_s_002598.png</td>\n",
       "      <td>8</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>minibike_s_000824.png</td>\n",
       "      <td>48</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>tram_s_000475.png</td>\n",
       "      <td>81</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>motorcycle_s_001856.png</td>\n",
       "      <td>48</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>streetcar_s_001848.png</td>\n",
       "      <td>81</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>step_rocket_s_000566.png</td>\n",
       "      <td>69</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>bicycle_s_000537.png</td>\n",
       "      <td>8</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    filenames  labels  row\n",
       "16          bike_s_000682.png       8   16\n",
       "30          bike_s_000127.png       8   30\n",
       "36     streetcar_s_000663.png      81   36\n",
       "48       tractor_s_001723.png      89   48\n",
       "73       tractor_s_000104.png      89   73\n",
       "76     bulldozer_s_000433.png      89   76\n",
       "93     minuteman_s_000073.png      69   93\n",
       "107         icbm_s_000392.png      69  107\n",
       "130        cycle_s_002598.png       8  130\n",
       "152     minibike_s_000824.png      48  152\n",
       "186         tram_s_000475.png      81  186\n",
       "195   motorcycle_s_001856.png      48  195\n",
       "196    streetcar_s_001848.png      81  196\n",
       "199  step_rocket_s_000566.png      69  199\n",
       "219      bicycle_s_000537.png       8  219"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8b8e695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenames</th>\n",
       "      <th>labels</th>\n",
       "      <th>row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>streetcar_s_000382.png</td>\n",
       "      <td>81</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sounding_rocket_s_000010.png</td>\n",
       "      <td>69</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>safety_bike_s_000390.png</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bike_s_000658.png</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>exocet_s_000376.png</td>\n",
       "      <td>69</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>dozer_s_001228.png</td>\n",
       "      <td>89</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>research_rocket_s_001220.png</td>\n",
       "      <td>69</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>velocipede_s_001744.png</td>\n",
       "      <td>8</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>bike_s_000643.png</td>\n",
       "      <td>8</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>streetcar_s_000124.png</td>\n",
       "      <td>81</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>bulldozer_s_001971.png</td>\n",
       "      <td>89</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>tractor_s_001551.png</td>\n",
       "      <td>89</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>bulldozer_s_001524.png</td>\n",
       "      <td>89</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>tractor_s_000668.png</td>\n",
       "      <td>89</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>ordinary_bicycle_s_000437.png</td>\n",
       "      <td>8</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         filenames  labels  row\n",
       "12          streetcar_s_000382.png      81   12\n",
       "13    sounding_rocket_s_000010.png      69   13\n",
       "27        safety_bike_s_000390.png       8   27\n",
       "28               bike_s_000658.png       8   28\n",
       "59             exocet_s_000376.png      69   59\n",
       "85              dozer_s_001228.png      89   85\n",
       "105   research_rocket_s_001220.png      69  105\n",
       "116        velocipede_s_001744.png       8  116\n",
       "161              bike_s_000643.png       8  161\n",
       "219         streetcar_s_000124.png      81  219\n",
       "230         bulldozer_s_001971.png      89  230\n",
       "262           tractor_s_001551.png      89  262\n",
       "283         bulldozer_s_001524.png      89  283\n",
       "299           tractor_s_000668.png      89  299\n",
       "319  ordinary_bicycle_s_000437.png       8  319"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31150d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./train_batch_classification/images\n",
    "!mkdir -p ./test_batch_classification/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1114010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(idx_image, channel, dataset):\n",
    "    #Grab the image data in row-major form\n",
    "    img = dataset[b'data'][idx_image]\n",
    "    \n",
    "    # Consolidated stacking/reshaping from earlier\n",
    "    target = np.dstack((\n",
    "            img[:1024].reshape(32, 32),\n",
    "            img[1024:2048].reshape(32, 32),\n",
    "            img[2048:].reshape(32, 32)\n",
    "    ))\n",
    "    \n",
    "    # Save the image\n",
    "    plt.imsave(f\"./{channel}/images/{dataset[b'filenames'][idx_image].decode('utf-8')}\", target)\n",
    "    \n",
    "    # Return any signal data you want for debugging\n",
    "    return\n",
    "\n",
    "for idx in df_train.index.values:\n",
    "    save_images(idx, 'train_batch_classification', dataset_train)\n",
    "    \n",
    "for idx in df_test.index.values:\n",
    "    save_images(idx, 'test_batch_classification', dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2fddce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"WORKING_BUCKET\"] = working_bucket\n",
    "!aws s3 sync ./train_batch_classification s3://${WORKING_BUCKET}/train_batch_classification/\n",
    "!aws s3 sync ./test_batch_classification s3://${WORKING_BUCKET}/test_batch_classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "daf64136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 48, 69, 81, 89]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers_type_vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9bff562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'bicycle', b'motorcycle', b'streetcar', b'rocket', b'tractor']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types_vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0728d410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8, b'bicycle'),\n",
       " (48, b'motorcycle'),\n",
       " (69, b'streetcar'),\n",
       " (81, b'rocket'),\n",
       " (89, b'tractor')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types_vehicles = list(zip(numbers_type_vehicle, types_vehicles))\n",
    "[type for type in types_vehicles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f07cac60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89, b'tractor')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types_vehicles[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d15d2d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 48, 69, 81, 89]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers_type_vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29f958db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12      81\n",
       "13      69\n",
       "27       8\n",
       "28       8\n",
       "59      69\n",
       "        ..\n",
       "9922    89\n",
       "9928     8\n",
       "9939     8\n",
       "9946    69\n",
       "9969    89\n",
       "Name: labels, Length: 500, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6e1e70",
   "metadata": {},
   "source": [
    "--- \n",
    "### Model Training\n",
    "\n",
    "For Image Classification, Sagemaker [also expects metadata](https://docs.aws.amazon.com/sagemaker/latest/dg/image-classification.html) e.g. in the form of TSV files with labels and filepaths. We can generate these using our Pandas DataFrames from earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3defbbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_index_vehicle(number_vehicle):\n",
    "    index_vehicle = 0\n",
    "    while number_vehicle != numbers_type_vehicle[index_vehicle]:\n",
    "        index_vehicle += 1\n",
    "    return index_vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a1328d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#return_index_vehicle(85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd3de324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_metadata_file(df, prefix):\n",
    "    df[\"s3_path\"] = df[\"filenames\"]\n",
    "    df[\"labels\"] = df[\"labels\"].apply(lambda x: return_index_vehicle(x))\n",
    "    return df[[\"row\", \"labels\", \"s3_path\"]].to_csv(\n",
    "        f\"{prefix}.lst\", sep=\"\\t\", index=False, header=False\n",
    "    )\n",
    "    \n",
    "to_metadata_file(df_train.copy(), \"train_batch_classification\")\n",
    "to_metadata_file(df_test.copy(), \"test_batch_classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33d14706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload .lst files\n",
    "client_s3.Bucket(working_bucket).Object('train_batch_classification.lst').upload_file('./train_batch_classification.lst')\n",
    "client_s3.Bucket(working_bucket).Object('test_batch_classification.lst').upload_file('./test_batch_classification.lst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7e4b708",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris\n",
    "\n",
    "# Use the image_uris function to retrieve the latest 'image-classification' image \n",
    "algo_image = image_uris.retrieve(framework='image-classification', region=region)\n",
    "s3_output_location = f\"s3://{working_bucket}/models/image_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d5c5543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://batch-classification-scones-project/models/image_model'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_output_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "949fc757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The local path where the model will save its checkpoints in the training container\n",
    "checkpoint_local_path=\"/opt/ml/checkpoints\" \n",
    "\n",
    "# The S3 URI to store the checkpoints\n",
    "checkpoint_s3_bucket=f\"s3://{working_bucket}/checkpoints\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a9e7b9",
   "metadata": {},
   "source": [
    "#### Choice of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e6ee7375",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters for spot instance\n",
    "use_spot_instances = True # Not simple to have spot capacity. Have to try many times. Perhaps I would try in another region, but all would have to be moved (s3...) \n",
    "max_run = 3600\n",
    "max_wait = 7200 if use_spot_instances else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "497da5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#supported instances for image classification prebuilt sagemaker algorithms\n",
    "# 'ml.p2.xlarge', 'ml.p2.8xlarge', 'ml.p2.16xlarge', 'ml.p3.2xlarge', 'ml.p3.8xlargeand', 'ml.p3.16xlarge'\n",
    "instance_training_type = 'ml.p3.2xlarge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c27e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uuid = uuid4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "57a4c882",
   "metadata": {},
   "outputs": [],
   "source": [
    "#supp\n",
    "\n",
    "img_classifier_model=sagemaker.estimator.Estimator(\n",
    "    ## TODO: define your estimator options  \n",
    "    algo_image,\n",
    "    role,\n",
    "    instance_count= 1,\n",
    "    #instance_type= 'ml.p2.xlarge',\n",
    "    instance_type= instance_training_type,\n",
    "    use_spot_instances= use_spot_instances,\n",
    "    max_run= max_run,\n",
    "    max_wait = max_wait,    \n",
    "    output_path= s3_output_location,\n",
    "    #name=\n",
    "    #checkpoint_s3_uri=checkpoint_s3_bucket,    \n",
    "    #checkpoint_local_path=checkpoint_local_path   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6f307239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(numbers_type_vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "29c0b455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_classifier_model.set_hyperparameters(\n",
    "#    image_shape= '3,32,32', # TODO: Fill in\n",
    "#    num_classes=2, # TODO: Fill in\n",
    "#    num_training_samples=1000, # TODO: fill in\n",
    "#    learning_rate=0.05\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1909a4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training_samples=2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "88b47c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters for training\n",
    "img_classifier_model.set_hyperparameters(\n",
    "    image_shape= '3,32,32', # TODO: Fill in\n",
    "    num_classes= len(numbers_type_vehicle), # TODO: Fill in\n",
    "    num_training_samples= num_training_samples, # TODO: fill in\n",
    "    learning_rate=0.01, \n",
    "    mini_batch_size= 64,\n",
    "    epochs=50\n",
    ")\n",
    "\n",
    "#{'num_classes': '3', 'num_training_samples': '1500', 'image_shape': '3,32,32', 'learning_rate': '0.01'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9dcc48fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = f\"s3://{working_bucket}/train_batch_classification/images/\"\n",
    "test_input  = f\"s3://{working_bucket}/test_batch_classification/images/\"\n",
    "train_lst  = f\"s3://{working_bucket}/train_batch_classification.lst\"\n",
    "test_lst  = f\"s3://{working_bucket}/test_batch_classification.lst\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "29150960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://batch-classification-scones-project/train_batch_classification/images/\n",
      "s3://batch-classification-scones-project/test_batch_classification/images/\n",
      "s3://batch-classification-scones-project/train_batch_classification.lst\n",
      "s3://batch-classification-scones-project/test_batch_classification.lst\n"
     ]
    }
   ],
   "source": [
    "print(train_input)\n",
    "print(test_input)\n",
    "print(train_lst)\n",
    "print(test_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a7a21cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.debugger import Rule, rule_configs\n",
    "from sagemaker.session import TrainingInput\n",
    "model_inputs = {\n",
    "        \"train\": sagemaker.inputs.TrainingInput(\n",
    "            s3_data=train_input,\n",
    "            content_type=\"application/x-image\"\n",
    "        ),\n",
    "        \"validation\": sagemaker.inputs.TrainingInput(\n",
    "            s3_data=test_input,\n",
    "            content_type=\"application/x-image\"\n",
    "        ),\n",
    "        \"train_lst\": sagemaker.inputs.TrainingInput(\n",
    "            s3_data=train_lst,\n",
    "            content_type=\"application/x-image\"\n",
    "        ),\n",
    "        \"validation_lst\": sagemaker.inputs.TrainingInput(\n",
    "            s3_data=test_lst,\n",
    "            content_type=\"application/x-image\"\n",
    "        )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4d22457d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-30 18:42:17 Starting - Starting the training job...\n",
      "2022-01-30 18:42:47 Starting - Launching requested ML instancesProfilerReport-1643568137: InProgress\n",
      "......\n",
      "2022-01-30 18:43:47 Starting - Preparing the instances for training........\n",
      "2022-01-30 18:45:07 Downloading - Downloading input data...\n",
      "2022-01-30 18:45:47 Training - Downloading the training image......\n",
      "2022-01-30 18:46:48 Training - Training image download completed. Training in progress.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:46:40 INFO 140223575467840] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/image_classification/default-input.json: {'use_pretrained_model': 0, 'num_layers': 152, 'epochs': 30, 'learning_rate': 0.1, 'lr_scheduler_factor': 0.1, 'optimizer': 'sgd', 'momentum': 0, 'weight_decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'eps': 1e-08, 'gamma': 0.9, 'mini_batch_size': 32, 'image_shape': '3,224,224', 'precision_dtype': 'float32'}\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:46:40 INFO 140223575467840] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'num_classes': '5', 'num_training_samples': '2500', 'epochs': '50', 'image_shape': '3,32,32', 'learning_rate': '0.01', 'mini_batch_size': '64'}\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:46:40 INFO 140223575467840] Final configuration: {'use_pretrained_model': 0, 'num_layers': 152, 'epochs': '50', 'learning_rate': '0.01', 'lr_scheduler_factor': 0.1, 'optimizer': 'sgd', 'momentum': 0, 'weight_decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'eps': 1e-08, 'gamma': 0.9, 'mini_batch_size': '64', 'image_shape': '3,32,32', 'precision_dtype': 'float32', 'num_classes': '5', 'num_training_samples': '2500'}\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:46:40 INFO 140223575467840] Searching for .lst files in /opt/ml/input/data/train_lst.\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:46:40 INFO 140223575467840] Creating record files for train_batch_classification.lst\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:46:41 INFO 140223575467840] Done creating record files...\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:46:41 INFO 140223575467840] Searching for .lst files in /opt/ml/input/data/validation_lst.\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:46:41 INFO 140223575467840] Creating record files for test_batch_classification.lst\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:46:41 INFO 140223575467840] Done creating record files...\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:46:41 INFO 140223575467840] use_pretrained_model: 0\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:46:41 INFO 140223575467840] multi_label: 0\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:46:41 INFO 140223575467840] Performing random weight initialization\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:46:41 INFO 140223575467840] ---- Parameters ----\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:46:41 INFO 140223575467840] num_layers: 152\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:46:41 INFO 140223575467840] data type: <class 'numpy.float32'>\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:46:41 INFO 140223575467840] epochs: 50\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:46:41 INFO 140223575467840] optimizer: sgd\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:46:41 INFO 140223575467840] momentum: 0.9\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:46:41 INFO 140223575467840] weight_decay: 0.0001\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:46:41 INFO 140223575467840] learning_rate: 0.01\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:46:41 INFO 140223575467840] num_training_samples: 2500\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:46:41 INFO 140223575467840] mini_batch_size: 64\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:46:41 INFO 140223575467840] image_shape: 3,32,32\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:46:41 INFO 140223575467840] num_classes: 5\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:46:41 INFO 140223575467840] augmentation_type: None\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:46:41 INFO 140223575467840] kv_store: device\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:46:41 INFO 140223575467840] checkpoint_frequency not set, will store the best model\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:46:41 INFO 140223575467840] --------------------\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:46:41 INFO 140223575467840] Setting number of threads: 7\u001b[0m\n",
      "\u001b[34m[18:46:51] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_ecl_Cuda_10.1.x.10365.0/AL2_x86_64/generic-flavor/src/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:46:57 INFO 140223575467840] Epoch[0] Batch [20]#011Speed: 206.325 samples/sec#011accuracy=0.244792\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:00 INFO 140223575467840] Epoch[0] Train-accuracy=0.298478\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:00 INFO 140223575467840] Epoch[0] Time cost=9.403\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:01 INFO 140223575467840] Epoch[0] Validation-accuracy=0.306641\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:01 INFO 140223575467840] Storing the best model with validation accuracy: 0.306641\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:01 INFO 140223575467840] Saved checkpoint to \"/opt/ml/model/image-classification-0001.params\"\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:05 INFO 140223575467840] Epoch[1] Batch [20]#011Speed: 351.051 samples/sec#011accuracy=0.456101\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:08 INFO 140223575467840] Epoch[1] Train-accuracy=0.471554\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:08 INFO 140223575467840] Epoch[1] Time cost=6.863\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:09 INFO 140223575467840] Epoch[1] Validation-accuracy=0.496094\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:09 INFO 140223575467840] Storing the best model with validation accuracy: 0.496094\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:10 INFO 140223575467840] Saved checkpoint to \"/opt/ml/model/image-classification-0002.params\"\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:13 INFO 140223575467840] Epoch[2] Batch [20]#011Speed: 356.473 samples/sec#011accuracy=0.549851\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:16 INFO 140223575467840] Epoch[2] Train-accuracy=0.559696\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:16 INFO 140223575467840] Epoch[2] Time cost=6.750\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:17 INFO 140223575467840] Epoch[2] Validation-accuracy=0.595703\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:17 INFO 140223575467840] Storing the best model with validation accuracy: 0.595703\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:18 INFO 140223575467840] Saved checkpoint to \"/opt/ml/model/image-classification-0003.params\"\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:21 INFO 140223575467840] Epoch[3] Batch [20]#011Speed: 357.916 samples/sec#011accuracy=0.634673\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:24 INFO 140223575467840] Epoch[3] Train-accuracy=0.653846\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:24 INFO 140223575467840] Epoch[3] Time cost=6.761\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:25 INFO 140223575467840] Epoch[3] Validation-accuracy=0.603516\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:25 INFO 140223575467840] Storing the best model with validation accuracy: 0.603516\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:26 INFO 140223575467840] Saved checkpoint to \"/opt/ml/model/image-classification-0004.params\"\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:29 INFO 140223575467840] Epoch[4] Batch [20]#011Speed: 357.151 samples/sec#011accuracy=0.684524\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:32 INFO 140223575467840] Epoch[4] Train-accuracy=0.697516\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:32 INFO 140223575467840] Epoch[4] Time cost=6.769\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:33 INFO 140223575467840] Epoch[4] Validation-accuracy=0.593750\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:37 INFO 140223575467840] Epoch[5] Batch [20]#011Speed: 358.843 samples/sec#011accuracy=0.770833\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:40 INFO 140223575467840] Epoch[5] Train-accuracy=0.748397\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:40 INFO 140223575467840] Epoch[5] Time cost=6.748\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:41 INFO 140223575467840] Epoch[5] Validation-accuracy=0.617188\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:41 INFO 140223575467840] Storing the best model with validation accuracy: 0.617188\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:41 INFO 140223575467840] Saved checkpoint to \"/opt/ml/model/image-classification-0006.params\"\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:45 INFO 140223575467840] Epoch[6] Batch [20]#011Speed: 356.868 samples/sec#011accuracy=0.773810\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:48 INFO 140223575467840] Epoch[6] Train-accuracy=0.772436\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:48 INFO 140223575467840] Epoch[6] Time cost=6.784\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:49 INFO 140223575467840] Epoch[6] Validation-accuracy=0.658203\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:49 INFO 140223575467840] Storing the best model with validation accuracy: 0.658203\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:49 INFO 140223575467840] Saved checkpoint to \"/opt/ml/model/image-classification-0007.params\"\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:53 INFO 140223575467840] Epoch[7] Batch [20]#011Speed: 359.529 samples/sec#011accuracy=0.808036\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:56 INFO 140223575467840] Epoch[7] Train-accuracy=0.802484\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:56 INFO 140223575467840] Epoch[7] Time cost=6.729\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:47:57 INFO 140223575467840] Epoch[7] Validation-accuracy=0.587891\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:01 INFO 140223575467840] Epoch[8] Batch [20]#011Speed: 358.334 samples/sec#011accuracy=0.847470\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:04 INFO 140223575467840] Epoch[8] Train-accuracy=0.844952\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:04 INFO 140223575467840] Epoch[8] Time cost=6.768\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:04 INFO 140223575467840] Epoch[8] Validation-accuracy=0.597656\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:09 INFO 140223575467840] Epoch[9] Batch [20]#011Speed: 352.748 samples/sec#011accuracy=0.873512\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:12 INFO 140223575467840] Epoch[9] Train-accuracy=0.869792\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:12 INFO 140223575467840] Epoch[9] Time cost=6.788\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:12 INFO 140223575467840] Epoch[9] Validation-accuracy=0.687500\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:13 INFO 140223575467840] Storing the best model with validation accuracy: 0.687500\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:13 INFO 140223575467840] Saved checkpoint to \"/opt/ml/model/image-classification-0010.params\"\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:16 INFO 140223575467840] Epoch[10] Batch [20]#011Speed: 360.671 samples/sec#011accuracy=0.908482\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:20 INFO 140223575467840] Epoch[10] Train-accuracy=0.910256\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:20 INFO 140223575467840] Epoch[10] Time cost=6.717\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:20 INFO 140223575467840] Epoch[10] Validation-accuracy=0.685547\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:24 INFO 140223575467840] Epoch[11] Batch [20]#011Speed: 358.067 samples/sec#011accuracy=0.943452\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:27 INFO 140223575467840] Epoch[11] Train-accuracy=0.927083\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:27 INFO 140223575467840] Epoch[11] Time cost=6.738\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:28 INFO 140223575467840] Epoch[11] Validation-accuracy=0.654297\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:32 INFO 140223575467840] Epoch[12] Batch [20]#011Speed: 359.212 samples/sec#011accuracy=0.933780\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:35 INFO 140223575467840] Epoch[12] Train-accuracy=0.929487\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:35 INFO 140223575467840] Epoch[12] Time cost=6.730\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:36 INFO 140223575467840] Epoch[12] Validation-accuracy=0.677734\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:40 INFO 140223575467840] Epoch[13] Batch [20]#011Speed: 358.493 samples/sec#011accuracy=0.945685\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:43 INFO 140223575467840] Epoch[13] Train-accuracy=0.931891\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:43 INFO 140223575467840] Epoch[13] Time cost=6.734\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:44 INFO 140223575467840] Epoch[13] Validation-accuracy=0.675781\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:48 INFO 140223575467840] Epoch[14] Batch [20]#011Speed: 361.245 samples/sec#011accuracy=0.939732\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:51 INFO 140223575467840] Epoch[14] Train-accuracy=0.933093\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:51 INFO 140223575467840] Epoch[14] Time cost=6.766\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:51 INFO 140223575467840] Epoch[14] Validation-accuracy=0.629464\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:55 INFO 140223575467840] Epoch[15] Batch [20]#011Speed: 358.925 samples/sec#011accuracy=0.944940\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:59 INFO 140223575467840] Epoch[15] Train-accuracy=0.945913\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:59 INFO 140223575467840] Epoch[15] Time cost=6.727\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:59 INFO 140223575467840] Epoch[15] Validation-accuracy=0.689453\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:48:59 INFO 140223575467840] Storing the best model with validation accuracy: 0.689453\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:00 INFO 140223575467840] Saved checkpoint to \"/opt/ml/model/image-classification-0016.params\"\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:03 INFO 140223575467840] Epoch[16] Batch [20]#011Speed: 354.225 samples/sec#011accuracy=0.959077\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:07 INFO 140223575467840] Epoch[16] Train-accuracy=0.952324\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:07 INFO 140223575467840] Epoch[16] Time cost=6.847\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:07 INFO 140223575467840] Epoch[16] Validation-accuracy=0.691406\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:08 INFO 140223575467840] Storing the best model with validation accuracy: 0.691406\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:08 INFO 140223575467840] Saved checkpoint to \"/opt/ml/model/image-classification-0017.params\"\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:11 INFO 140223575467840] Epoch[17] Batch [20]#011Speed: 362.286 samples/sec#011accuracy=0.951637\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:15 INFO 140223575467840] Epoch[17] Train-accuracy=0.948317\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:15 INFO 140223575467840] Epoch[17] Time cost=6.680\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:15 INFO 140223575467840] Epoch[17] Validation-accuracy=0.664062\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:19 INFO 140223575467840] Epoch[18] Batch [20]#011Speed: 359.913 samples/sec#011accuracy=0.968750\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:22 INFO 140223575467840] Epoch[18] Train-accuracy=0.964744\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:22 INFO 140223575467840] Epoch[18] Time cost=6.714\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:23 INFO 140223575467840] Epoch[18] Validation-accuracy=0.667969\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:27 INFO 140223575467840] Epoch[19] Batch [20]#011Speed: 359.686 samples/sec#011accuracy=0.969494\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:30 INFO 140223575467840] Epoch[19] Train-accuracy=0.974760\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:30 INFO 140223575467840] Epoch[19] Time cost=6.696\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:31 INFO 140223575467840] Epoch[19] Validation-accuracy=0.703125\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:31 INFO 140223575467840] Storing the best model with validation accuracy: 0.703125\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:31 INFO 140223575467840] Saved checkpoint to \"/opt/ml/model/image-classification-0020.params\"\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:35 INFO 140223575467840] Epoch[20] Batch [20]#011Speed: 361.352 samples/sec#011accuracy=0.991071\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:38 INFO 140223575467840] Epoch[20] Train-accuracy=0.987580\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:38 INFO 140223575467840] Epoch[20] Time cost=6.695\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:39 INFO 140223575467840] Epoch[20] Validation-accuracy=0.747768\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:39 INFO 140223575467840] Storing the best model with validation accuracy: 0.747768\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:39 INFO 140223575467840] Saved checkpoint to \"/opt/ml/model/image-classification-0021.params\"\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:43 INFO 140223575467840] Epoch[21] Batch [20]#011Speed: 361.024 samples/sec#011accuracy=0.991071\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:46 INFO 140223575467840] Epoch[21] Train-accuracy=0.986779\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:46 INFO 140223575467840] Epoch[21] Time cost=6.695\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:46 INFO 140223575467840] Epoch[21] Validation-accuracy=0.708984\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:51 INFO 140223575467840] Epoch[22] Batch [20]#011Speed: 361.120 samples/sec#011accuracy=0.981399\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:54 INFO 140223575467840] Epoch[22] Train-accuracy=0.981170\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:54 INFO 140223575467840] Epoch[22] Time cost=6.685\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:54 INFO 140223575467840] Epoch[22] Validation-accuracy=0.710938\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:49:58 INFO 140223575467840] Epoch[23] Batch [20]#011Speed: 359.451 samples/sec#011accuracy=0.984375\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:50:01 INFO 140223575467840] Epoch[23] Train-accuracy=0.984776\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:50:01 INFO 140223575467840] Epoch[23] Time cost=6.721\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:50:02 INFO 140223575467840] Epoch[23] Validation-accuracy=0.710938\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:50:06 INFO 140223575467840] Epoch[24] Batch [20]#011Speed: 352.962 samples/sec#011accuracy=0.986607\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:50:09 INFO 140223575467840] Epoch[24] Train-accuracy=0.987179\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:50:09 INFO 140223575467840] Epoch[24] Time cost=6.791\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:50:10 INFO 140223575467840] Epoch[24] Validation-accuracy=0.730469\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:50:14 INFO 140223575467840] Epoch[25] Batch [20]#011Speed: 360.929 samples/sec#011accuracy=0.993304\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:50:17 INFO 140223575467840] Epoch[25] Train-accuracy=0.989583\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:50:17 INFO 140223575467840] Epoch[25] Time cost=6.732\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:50:18 INFO 140223575467840] Epoch[25] Validation-accuracy=0.736607\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:50:22 INFO 140223575467840] Epoch[26] Batch [20]#011Speed: 359.159 samples/sec#011accuracy=0.994048\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:50:25 INFO 140223575467840] Epoch[26] Train-accuracy=0.994792\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:50:25 INFO 140223575467840] Epoch[26] Time cost=6.699\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:50:26 INFO 140223575467840] Epoch[26] Validation-accuracy=0.707031\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:50:30 INFO 140223575467840] Epoch[27] Batch [20]#011Speed: 359.826 samples/sec#011accuracy=0.995536\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:50:33 INFO 140223575467840] Epoch[27] Train-accuracy=0.995994\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:50:33 INFO 140223575467840] Epoch[27] Time cost=6.699\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:50:33 INFO 140223575467840] Epoch[27] Validation-accuracy=0.730469\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:50:37 INFO 140223575467840] Epoch[28] Batch [20]#011Speed: 359.824 samples/sec#011accuracy=0.999256\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:50:40 INFO 140223575467840] Epoch[28] Train-accuracy=0.998798\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:50:40 INFO 140223575467840] Epoch[28] Time cost=6.711\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:50:41 INFO 140223575467840] Epoch[28] Validation-accuracy=0.722656\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:50:45 INFO 140223575467840] Epoch[29] Batch [20]#011Speed: 359.628 samples/sec#011accuracy=0.996280\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:50:48 INFO 140223575467840] Epoch[29] Train-accuracy=0.995994\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:50:48 INFO 140223575467840] Epoch[29] Time cost=6.702\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:50:49 INFO 140223575467840] Epoch[29] Validation-accuracy=0.738281\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:50:53 INFO 140223575467840] Epoch[30] Batch [20]#011Speed: 357.774 samples/sec#011accuracy=0.997768\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:50:56 INFO 140223575467840] Epoch[30] Train-accuracy=0.996795\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:50:56 INFO 140223575467840] Epoch[30] Time cost=6.709\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:50:56 INFO 140223575467840] Epoch[30] Validation-accuracy=0.743304\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:51:00 INFO 140223575467840] Epoch[31] Batch [20]#011Speed: 357.534 samples/sec#011accuracy=0.999256\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:51:04 INFO 140223575467840] Epoch[31] Train-accuracy=0.999599\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:51:04 INFO 140223575467840] Epoch[31] Time cost=6.733\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:51:04 INFO 140223575467840] Epoch[31] Validation-accuracy=0.724609\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:51:08 INFO 140223575467840] Epoch[32] Batch [20]#011Speed: 349.180 samples/sec#011accuracy=0.999256\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:51:13 INFO 140223575467840] Epoch[32] Train-accuracy=0.998798\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:51:13 INFO 140223575467840] Epoch[32] Time cost=8.146\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:51:13 INFO 140223575467840] Epoch[32] Validation-accuracy=0.724609\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:51:18 INFO 140223575467840] Epoch[33] Batch [20]#011Speed: 361.848 samples/sec#011accuracy=0.998512\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:51:21 INFO 140223575467840] Epoch[33] Train-accuracy=0.998798\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:51:21 INFO 140223575467840] Epoch[33] Time cost=6.678\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:51:21 INFO 140223575467840] Epoch[33] Validation-accuracy=0.738281\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:51:25 INFO 140223575467840] Epoch[34] Batch [20]#011Speed: 357.937 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:51:28 INFO 140223575467840] Epoch[34] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:51:28 INFO 140223575467840] Epoch[34] Time cost=6.740\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:51:29 INFO 140223575467840] Epoch[34] Validation-accuracy=0.744141\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:51:33 INFO 140223575467840] Epoch[35] Batch [20]#011Speed: 360.784 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:51:36 INFO 140223575467840] Epoch[35] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:51:36 INFO 140223575467840] Epoch[35] Time cost=6.700\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:51:37 INFO 140223575467840] Epoch[35] Validation-accuracy=0.742188\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:51:41 INFO 140223575467840] Epoch[36] Batch [20]#011Speed: 361.159 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:51:44 INFO 140223575467840] Epoch[36] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:51:44 INFO 140223575467840] Epoch[36] Time cost=6.687\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:51:44 INFO 140223575467840] Epoch[36] Validation-accuracy=0.754464\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:51:45 INFO 140223575467840] Storing the best model with validation accuracy: 0.754464\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:51:45 INFO 140223575467840] Saved checkpoint to \"/opt/ml/model/image-classification-0037.params\"\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:51:49 INFO 140223575467840] Epoch[37] Batch [20]#011Speed: 359.922 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:51:52 INFO 140223575467840] Epoch[37] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:51:52 INFO 140223575467840] Epoch[37] Time cost=6.682\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:51:52 INFO 140223575467840] Epoch[37] Validation-accuracy=0.734375\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:51:56 INFO 140223575467840] Epoch[38] Batch [20]#011Speed: 358.985 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:00 INFO 140223575467840] Epoch[38] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:00 INFO 140223575467840] Epoch[38] Time cost=6.764\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:00 INFO 140223575467840] Epoch[38] Validation-accuracy=0.734375\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:04 INFO 140223575467840] Epoch[39] Batch [20]#011Speed: 357.594 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:07 INFO 140223575467840] Epoch[39] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:07 INFO 140223575467840] Epoch[39] Time cost=6.779\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:08 INFO 140223575467840] Epoch[39] Validation-accuracy=0.742188\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:12 INFO 140223575467840] Epoch[40] Batch [20]#011Speed: 360.825 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:15 INFO 140223575467840] Epoch[40] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:15 INFO 140223575467840] Epoch[40] Time cost=6.724\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:16 INFO 140223575467840] Epoch[40] Validation-accuracy=0.742188\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:20 INFO 140223575467840] Epoch[41] Batch [20]#011Speed: 353.595 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:23 INFO 140223575467840] Epoch[41] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:23 INFO 140223575467840] Epoch[41] Time cost=6.796\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:24 INFO 140223575467840] Epoch[41] Validation-accuracy=0.754464\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:28 INFO 140223575467840] Epoch[42] Batch [20]#011Speed: 359.787 samples/sec#011accuracy=0.999256\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:31 INFO 140223575467840] Epoch[42] Train-accuracy=0.999199\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:31 INFO 140223575467840] Epoch[42] Time cost=6.707\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:31 INFO 140223575467840] Epoch[42] Validation-accuracy=0.724609\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:35 INFO 140223575467840] Epoch[43] Batch [20]#011Speed: 360.553 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:38 INFO 140223575467840] Epoch[43] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:38 INFO 140223575467840] Epoch[43] Time cost=6.698\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:39 INFO 140223575467840] Epoch[43] Validation-accuracy=0.728516\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:43 INFO 140223575467840] Epoch[44] Batch [20]#011Speed: 361.048 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:46 INFO 140223575467840] Epoch[44] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:46 INFO 140223575467840] Epoch[44] Time cost=6.691\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:47 INFO 140223575467840] Epoch[44] Validation-accuracy=0.732422\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:51 INFO 140223575467840] Epoch[45] Batch [20]#011Speed: 361.359 samples/sec#011accuracy=0.998512\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:54 INFO 140223575467840] Epoch[45] Train-accuracy=0.998397\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:54 INFO 140223575467840] Epoch[45] Time cost=6.700\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:55 INFO 140223575467840] Epoch[45] Validation-accuracy=0.732422\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:52:59 INFO 140223575467840] Epoch[46] Batch [20]#011Speed: 361.676 samples/sec#011accuracy=0.999256\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:53:02 INFO 140223575467840] Epoch[46] Train-accuracy=0.999199\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:53:02 INFO 140223575467840] Epoch[46] Time cost=6.704\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:53:02 INFO 140223575467840] Epoch[46] Validation-accuracy=0.732143\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:53:06 INFO 140223575467840] Epoch[47] Batch [20]#011Speed: 354.080 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:53:09 INFO 140223575467840] Epoch[47] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:53:09 INFO 140223575467840] Epoch[47] Time cost=6.791\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:53:10 INFO 140223575467840] Epoch[47] Validation-accuracy=0.740234\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:53:14 INFO 140223575467840] Epoch[48] Batch [20]#011Speed: 357.596 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:53:17 INFO 140223575467840] Epoch[48] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:53:17 INFO 140223575467840] Epoch[48] Time cost=6.719\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:53:18 INFO 140223575467840] Epoch[48] Validation-accuracy=0.750000\u001b[0m\n",
      "\n",
      "2022-01-30 18:53:29 Uploading - Uploading generated training model\u001b[34m[01/30/2022 18:53:22 INFO 140223575467840] Epoch[49] Batch [20]#011Speed: 360.908 samples/sec#011accuracy=0.999256\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:53:25 INFO 140223575467840] Epoch[49] Train-accuracy=0.999599\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:53:25 INFO 140223575467840] Epoch[49] Time cost=6.703\u001b[0m\n",
      "\u001b[34m[01/30/2022 18:53:26 INFO 140223575467840] Epoch[49] Validation-accuracy=0.736328\u001b[0m\n",
      "\n",
      "2022-01-30 18:54:30 Completed - Training job completed\n",
      "ProfilerReport-1643568137: NoIssuesFound\n",
      "Training seconds: 542\n",
      "Billable seconds: 163\n",
      "Managed Spot Training savings: 69.9%\n"
     ]
    }
   ],
   "source": [
    "img_classifier_model.fit(model_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1947b89e",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "### Deployment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "18692b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://batch-classification-scones-project/data_capture'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"s3://{working_bucket}/data_capture\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dd8f1e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "data_capture_config = DataCaptureConfig(\n",
    "    enable_capture= True,\n",
    "    sampling_percentage= 100,\n",
    "    destination_s3_uri= f\"s3://{working_bucket}/data_capture\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c7fc8fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'batch_classification-TIME-2022-01-30-19-34-46-911066-ID-5b7491b7-bbc2-4bcd-b8d0-4481acb9fb04'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'batch_classification-TIME-{dt.now().strftime(\"%Y-%m-%d-%H-%M-%S-%f\")}-ID-{str(uuid4())}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "de687308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------!batch-classification-TIME-2022-01-30-19-36-14-465184\n"
     ]
    }
   ],
   "source": [
    "deployment = img_classifier_model.deploy(\n",
    "    data_capture_config=data_capture_config,\n",
    "    initial_instance_count= 1, \n",
    "    instance_type= 'ml.t2.medium', \n",
    "    endpoint_name= f'batch-classification-TIME-{dt.now().strftime(\"%Y-%m-%d-%H-%M-%S-%f\")}'\n",
    "    )\n",
    "\n",
    "endpoint = deployment.endpoint_name\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51cc5da",
   "metadata": {},
   "source": [
    "--- \n",
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d8ef0126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#endpoint_name=\"batch-classification-TIME-2022-01-30-19-36-14-465184\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "17fd2ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "predictor = Predictor(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "76f12320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import IdentitySerializer\n",
    "\n",
    "predictor.serializer = IdentitySerializer(\"image/png\")\n",
    "with open(\"./test/images/bicycle_s_001789.png\", \"rb\") as f:\n",
    "    payload = f.read()\n",
    "\n",
    "inference = predictor.predict(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8d408968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'[0.9782111048698425, 0.013572802767157555, 0.006240911316126585, 0.00013658084208145738, 0.0018385974690318108]'\n"
     ]
    }
   ],
   "source": [
    "print(inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a94715df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8, b'bicycle'),\n",
       " (48, b'motorcycle'),\n",
       " (69, b'streetcar'),\n",
       " (81, b'rocket'),\n",
       " (89, b'tractor')]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types_vehicles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6728c99",
   "metadata": {},
   "source": [
    "--- \n",
    "#### Data capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8d36bfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path_of_data_capture = './batch_classification/captured_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c84e44d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://batch-classification-scones-project/data_capture/'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "48bfad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "# In S3 your data will be saved to a datetime-aware path\n",
    "# Find a path related to a datetime you're interested in\n",
    "data_path = f\"s3://{working_bucket}/data_capture/\" \n",
    "\n",
    "S3Downloader.download(data_path, local_path_of_data_capture)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "89f1600d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['batch-classification-TIME-2022-01-30-19-36-14-465184']\n"
     ]
    }
   ],
   "source": [
    "file_handles = os.listdir(local_path_of_data_capture)\n",
    "print(file_handles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f9f781b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = []\n",
    "# List the file names we downloaded\n",
    "for root, dirs, files in os.walk(local_path_of_data_capture, topdown=False):\n",
    "    for name in files:\n",
    "        with jsonlines.open(os.path.join(root, name)) as f:\n",
    "            for line in f:\n",
    "                json_data.append(line)\n",
    "         #       print(line)\n",
    "        #print(\"###############\" + os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101a408a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "json_data = []\n",
    "# List the file names we downloaded\n",
    "for root, dirs, files in os.walk(local_path_of_data_capture, topdown=False):\n",
    "    for name in files:\n",
    "        with jsonlines.open(os.path.join(root, name)) as f:\n",
    "            json_data.append(f.read())\n",
    "        \n",
    "        print(os.path.join(root, name))\n",
    "'''        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3bc8e822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "04a7a1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.900000e+02</td>\n",
       "      <td>2.900000e+02</td>\n",
       "      <td>2.900000e+02</td>\n",
       "      <td>2.900000e+02</td>\n",
       "      <td>2.900000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.897513e-01</td>\n",
       "      <td>2.105317e-01</td>\n",
       "      <td>1.736046e-01</td>\n",
       "      <td>2.189568e-01</td>\n",
       "      <td>2.071557e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.508609e-01</td>\n",
       "      <td>3.699147e-01</td>\n",
       "      <td>3.506887e-01</td>\n",
       "      <td>3.621098e-01</td>\n",
       "      <td>3.544176e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.527180e-10</td>\n",
       "      <td>4.916572e-11</td>\n",
       "      <td>3.973015e-12</td>\n",
       "      <td>5.445946e-11</td>\n",
       "      <td>1.010907e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.729072e-06</td>\n",
       "      <td>1.207267e-05</td>\n",
       "      <td>5.960154e-07</td>\n",
       "      <td>1.024017e-05</td>\n",
       "      <td>3.855163e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.856085e-04</td>\n",
       "      <td>1.818875e-03</td>\n",
       "      <td>5.460895e-05</td>\n",
       "      <td>1.274047e-03</td>\n",
       "      <td>3.262654e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.112920e-01</td>\n",
       "      <td>2.055986e-01</td>\n",
       "      <td>4.117918e-02</td>\n",
       "      <td>2.835635e-01</td>\n",
       "      <td>1.708589e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999930e-01</td>\n",
       "      <td>9.999484e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3             4\n",
       "count  2.900000e+02  2.900000e+02  2.900000e+02  2.900000e+02  2.900000e+02\n",
       "mean   1.897513e-01  2.105317e-01  1.736046e-01  2.189568e-01  2.071557e-01\n",
       "std    3.508609e-01  3.699147e-01  3.506887e-01  3.621098e-01  3.544176e-01\n",
       "min    3.527180e-10  4.916572e-11  3.973015e-12  5.445946e-11  1.010907e-10\n",
       "25%    8.729072e-06  1.207267e-05  5.960154e-07  1.024017e-05  3.855163e-06\n",
       "50%    7.856085e-04  1.818875e-03  5.460895e-05  1.274047e-03  3.262654e-03\n",
       "75%    1.112920e-01  2.055986e-01  4.117918e-02  2.835635e-01  1.708589e-01\n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  9.999930e-01  9.999484e-01"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simple_getter(obj):\n",
    "    inferences = obj[\"captureData\"][\"endpointOutput\"][\"data\"]\n",
    "    timestamp = obj[\"eventMetadata\"][\"inferenceTime\"]\n",
    "    return json.loads(inferences), timestamp\n",
    "\n",
    "range(len(json_data))\n",
    "list_max_inferences = [max(simple_getter(json_data[idx])[0]) for idx in range(len(json_data))]\n",
    "probabilities= [simple_getter(json_data[idx])[0] for idx in range(len(json_data))]\n",
    "df_probabilities_result = pd.DataFrame(probabilities)\n",
    "df_probabilities_result.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2f5b1543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.30821916460990906,\n",
       " 0.0011776452884078026,\n",
       " 0.003933131229132414,\n",
       " 0.6632261872291565,\n",
       " 0.02344389632344246]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list_max_inferences[8]\n",
    "probabilities[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0110d72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1     2     3     4\n",
       "0   0.98  0.01  0.01  0.00  0.00\n",
       "1   0.00  1.00  0.00  0.00  0.00\n",
       "2   0.02  0.87  0.00  0.00  0.11\n",
       "3   0.00  1.00  0.00  0.00  0.00\n",
       "4   0.02  0.87  0.00  0.00  0.11\n",
       "5   0.98  0.01  0.01  0.00  0.00\n",
       "6   0.00  1.00  0.00  0.00  0.00\n",
       "7   1.00  0.00  0.00  0.00  0.00\n",
       "8   0.31  0.00  0.00  0.66  0.02\n",
       "9   0.02  0.87  0.00  0.00  0.11\n",
       "10  0.00  1.00  0.00  0.00  0.00\n",
       "11  1.00  0.00  0.00  0.00  0.00\n",
       "12  0.31  0.00  0.00  0.66  0.02\n",
       "13  0.02  0.87  0.00  0.00  0.11\n",
       "14  0.00  0.00  1.00  0.00  0.00\n",
       "15  0.00  0.00  0.00  0.65  0.35\n",
       "16  0.70  0.00  0.00  0.13  0.17\n",
       "17  1.00  0.00  0.00  0.00  0.00\n",
       "18  0.00  0.00  0.00  1.00  0.00\n",
       "19  0.00  0.00  1.00  0.00  0.00"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_probabilities_result.head(20).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb7e683",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow2_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
